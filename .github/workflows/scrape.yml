name: Scrape products

on:
  schedule:
    - cron: "0 0 * * *"      # 00:00 UTC daily (midnight)
  workflow_dispatch:         # allow manual runs

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 1440
    concurrency:
      group: scrape-${{ github.ref }}
      cancel-in-progress: true

    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      USER_AGENT: ${{ secrets.USER_AGENT }}
      HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
      HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
      EMBEDDINGS_MODEL: "google/siglip-large-patch16-384"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install --no-cache-dir -r requirements.txt

      - name: Install Playwright browsers
        run: playwright install chromium

      - name: Run scraper (all stores, with sync)
        run: |
          echo "Starting scraper at $(date)"
          python -m scraper.cli --sync
          echo "Completed scraper at $(date)"
